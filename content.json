{"posts":[{"title":"三篇图像动画论文的比较(FOMM,AA,SDEMT)","text":"FOMM和AA是很经典的论文，都来自作者Aliaksandr Siarohin，最近有一篇新论文在此基础上做了较大的改进，给出的效果看起来也很好，因此总结三个论文的内容。 FOMM AA Self-appearance-aided Differential Evolution for Motion Transfer FOMM motion representation包含稀疏动作估计和稠密动作估计。 稀疏动作使用$\\mathcal{T}_{S\\leftarrow R}(p_k),\\mathcal{T}_{D\\leftarrow R}(p_k)$来计算D中每个关键点处到S的仿射变换，具体方法是用泰勒展开，然后将涉及到$\\mathcal{T}_{S\\leftarrow R}(p_k),\\mathcal{T}_{D\\leftarrow R}(p_k)$之外的变化都用$\\mathcal{T}_{S\\leftarrow R}(p_k),\\mathcal{T}_{D\\leftarrow R}(p_k)$来代替。 \\mathcal{T_{S\\leftarrow D}}(z) \\approx \\mathcal{T_{S\\leftarrow R}}(p_k) + J_k(z-\\mathcal{T_{D\\leftarrow R}}(p_k))稠密动作用$\\mathcal{T}_{S\\leftarrow R}(p_k),\\mathcal{T}_{D\\leftarrow R}(p_k)$的高斯分布之差计算热力图来找出变换发生的位置。对S进行稀疏动作的逆变换，得到K个结果(每个关键点一个变换)。然后将热力图和S变换结果一起喂给U-net，预测K+1个mask作为每个关键点上稀疏动作的权值，多出的一个mask用于处理背景。稠密动作就是各个关键点的稀疏动作的加权和。 extraction使用u-net分别提取参考帧到两个输入图像的仿射变换$\\mathcal{T}_{S\\leftarrow R}(p_k),\\mathcal{T}_{D\\leftarrow R}(p_k)$，每个关键点对应一个变换。还额外输出一个遮挡图的通道。 transfer用稠密动作warp输入图像，然后用遮挡图计算阿达马乘积，最后通过一个解码器处理得到最终结果。 Articulated Animationmotion representation包含稀疏动作估计和稠密动作估计。论文和代码里热力图的概念被重复用在两个地方，一个是指输入图像提取出来的热力图，相当于特征点，另一个是稠密动作里用高斯分布得到的热力图，用于找出发生变换的位置。 稀疏动作使用PCA处理热力图的协方差得到仿射变换的线性变换的部分，热力图的均值作为仿射变换的偏移量，总共5个自由度，加上背景的恒等变换就得到稀疏动作。 稠密动作和FOMM的做法完全一样（包括使用的神经网络结构），稠密动作就是各个关键点的稀疏动作的加权和。 extraction使用U-net结构提取输入图像的特征图，经过一层卷积和softmax，得到热力图。 transfer和FOMM一样。 Self-appearance-aided Differential Evolution for Motion Transfermotion representation计算关键点的差值作为神经网络的输入，回归出系数来加权关键点的差值作为稀疏动作，同时作为微分方程 \\frac{d \\mathscr{T}}{d t}=\\mathscr{F}_{E}\\left(\\mathscr{T}^{(t)}, t\\right), \\quad \\text { for } t \\in[0,1]的初值$\\mathscr{F}^{(0)}$：，两侧积分就得到稠密动作。 extraction用编码器解码器网络获得S和D的关键点。 transfer 用特征提取网络提取输入图像的特征$\\mathbb{F}_{\\mathbb{S}}$。 将$\\mathbb{F}_{\\mathbb{S}}$用稠密动作进行扭曲得到$\\widetilde{\\mathbb{F}}_{\\mathbb{S D}}$。 扭曲后用$\\mathscr{F}_A$来预测self-appearance流变形场$\\mathscr{T}_{App}$，$\\mathscr{T}_{App}$是用来扭曲原区域到缺失区域的（流）特征的。 计算$\\mathbb{F}_{A p p}=\\mathscr{T}_{A p p} \\circ \\widetilde{\\mathbb{F}}_{\\mathbb{S D}}$。 用生成器$\\mathscr{F}_G$为N个不同视角的view输出置信度掩码$C^{(j)}$，每个视角的置信度掩码各自进行归一化：$\\widetilde{C}^{(j)}(\\mathbf{x})=C^{(j)}(\\mathbf{x}) / \\sum_{j=0}^{N} C^{(j)}(\\mathbf{x})$。 用置信度掩码对$\\mathbb{F}_{A p p} ,\\widetilde{\\mathbb{F}}_{\\mathbb{S D}}$分别计算加权和： \\overline{\\mathbb{F}}_{A p p}=\\sum_{j=1}^{N} \\widetilde{C}^{(j)} \\mathbb{F}_{A p p}^{(j)}, \\quad \\overline{\\widetilde{\\mathbb{F}}}_{\\mathbb{D}}=\\sum_{j=1}^{N} \\widetilde{C}^{(j)} \\widetilde{\\mathbb{F}}_\\mathbb{SD}^{(j)} 只有一个视图时，用$\\mathbb{F}_{A p p} ,\\widetilde{\\mathbb{F}}_{\\mathbb{S D}}$连接起来喂给$\\mathscr{F}_G$的编码器部分用于生成图像。有多个时，用加权后的连接起来喂给$\\mathscr{F}_G$的编码器部分用于生成图像。 总结差别 FOMM和Articulated Animation是同一个人的工作，只有稀疏动作表示是不一样的，提取特征里后者只是多了生成热力图的步骤，Articulated Animation简化了计算稀疏动作的过程，用PCA方法和热力图的均值直接获得仿射变换，非常简洁。 Self-appearance-aided Differential Evolution for Motion Transfer使用解微分方程的方法计算动作，原因是neural-ODEs已被证明能够捕捉复杂的变换，可微动作演化可以泛化稀疏动作的预测（我觉得意思是不会因为不同对象或者数据集效果差别很大），同时避免雅克比矩阵和SVD的大量计算。 优点 Articulated Animation认为PCA可以更好的描述动作，所以用PCA来获得仿射变换矩阵的线性部分的参数。 Self-appearance-aided Differential Evolution for Motion Transfer 里指出它的方法泛化了FOMM，AA，Monkey-Net方法。 Self-appearance-aided Differential Evolution for Motion Transfer 在CSIM上与FOMM,AA拉开很大的距离。即该方法相比FOMM,AA能更好的保留原图像的特征。 Self-appearance-aided Differential Evolution for Motion Transfer 泛化能力很好，在A训练集上训练后，在B训练集上依然效果很好。比如卡通动画生成中，该论文的方法能很好的保留个体特征，而FOMM和AA很差。 缺点 FOMM在提取稀疏动作的时候用了泰勒展开，非常繁琐。 Articulated Animation里指出FOMM这类用关键点的方法在处理物体边界内的动作会出现不真实的效果。 Articulated Animation认为该论文的方法的泛化能力较弱，生成非活物的动画有难度，也就是说生成素描动画效果不会很好。 Self-appearance-aided Differential Evolution for Motion Transfer的网络结构太大，训练时间久。","link":"/2021/12/13/FOMM-AA-SDEMT/"},{"title":"JOKR笔记","text":"JOKR: Joint Keypoint Representation for Unsupervised Cross-Domain Motion Retargeting摘要原视频和目标视频形状不同时，之前专注于特定对象先验的方法就会失败，作者提出联合关键点表达可以捕捉原视频和目标视频都有的动作，而且不需要物体先验或者数据采集。使用domain confusion项有利于对于两个domain的动作的一致的部分的解耦，可区分的外观和动作使得捕捉其中一个视频动作同时描绘另一个视频的风格的视频得以生成。 为处理物体有不同比例缩放或者不同方向的情形，作者应用了JOKR之间的仿射变换。这使得表达具有仿射不变性。 方法目标视频使用的外观来自视频A，动作来自视频B，共$N_a$和$N_b$帧。分割图$s_{a,i},s_{b,i}$是给定的数据，或者是通过现成的图像分割网络得到。 形状不变表达使用JOKR作为瓶颈。用无监督关键点提取器E，提取K个关键点$k_{a,i}$，提取器采用U-Net的做法，提取热力图$h_{a,i}$（a代表视频，i代表帧序号）来确定关键点位置。 为做到几何和外观的解耦，生成过程有两步： 给定$h_{a,i}$，生成器$G_{A}$被训练来输出一个同时对应提取到的关键点和物体形状的剪影。为减少参数数量，$G_{A},G_{B}$共用权重，除了最后一层。类似的，E也被用于两个视频。给定帧$a_i,b_j$，生成的剪影要最小化这个MSE loss。 \\mathcal{L}_{seg}=\\sum_{i=0}^{N_A-1}||G_A(E(a_i))-s_{a,i}||_2+\\sum_{j=0}^{N_B-1}||G_B(E(b_i))-s_{b,j}||_2训练生成器$R_A,R_B$来转换得到的分割图到原图上，因此添加了纹理。重建和感知损失为： \\begin{gathered} \\mathcal{L}_{L 1}=\\sum_{i=0}^{N_{A}-1}\\left\\|R_{A}\\left(G_{A}\\left(E\\left(a_{i}\\right)\\right)\\right)-a_{i}\\right\\|_{1}+\\sum_{j=0}^{N_{B}-1}\\left\\|R_{A}\\left(G_{B}\\left(E\\left(b_{j}\\right)\\right)\\right)-b_{j}\\right\\|_{1} \\\\ \\mathcal{L}_{\\text {LPIPS }}=\\sum_{i=0}^{N_{A}-1}\\left\\|\\mathcal{F}\\left(R_{A}\\left(G_{A}\\left(E\\left(a_{i}\\right)\\right)\\right)\\right)-\\mathcal{F}\\left(a_{i}\\right)\\right\\|_{2}+\\sum_{j=0}^{N_{B}-1}\\left\\|\\mathcal{F}\\left(R_{A}\\left(G_{B}\\left(E\\left(b_{j}\\right)\\right)\\right)\\right)-\\mathcal{F}\\left(b_{j}\\right)\\right\\|_{2} \\end{gathered}$\\mathcal{F}$是特征提取器。 共享表达AB视频描绘的物体可能来自不同domain，所以提取的关键点对于各自的视频可能有不同的语义信息。因此作者强制编码的关键点来自共享的分布，从而鼓励关键点捕捉同时来自两个视频的动作。AB的特定风格在生成器的权重里编码。为施加共享的分布，作者使用domain confusion loss。 此外还用一个判别器来区分A和B的domain的关键点，编码器被训练来欺骗他。 \\mathcal{L}_{\\mathrm{DC}}=\\sum_{i=0}^{N_{A}-1} \\ell_{\\text {bce }}\\left(D\\left(k_{a, i}\\right), 1\\right)+\\sum_{j=0}^{N_{B}-1} \\ell_{\\text {bce }}\\left(D\\left(k_{b, j}\\right), 1\\right)$\\ell_{bce}=-(q\\log(p)+(1-q)\\log(1-p))$是二元交叉熵损失函数。 关键点提取器尝试使得关键点分布无法区分，同时判别器做对抗它的训练： \\mathcal{L}_{\\mathrm{D}}=\\sum_{i=0}^{N_{A}-1} \\ell_{\\text {bce }}\\left(D\\left(k_{a, i}\\right), 0\\right)+\\sum_{j=0}^{N_{B}-1} \\ell_{\\text {bce }}\\left(D\\left(k_{b, j}\\right), 1\\right)时间连贯性为保证生成的视频是时间连贯的，即生成的动作平滑无抖动。应用时间正则化在生成的关键点上，最小化相邻帧之间的关键点的距离。 \\mathcal{L}_{\\mathrm{tmp}}=\\sum_{i=0}^{N_{A}-1}\\left\\|k_{a, i}-k_{a, i+1}\\right\\|_{2}+\\sum_{j=0}^{N_{B}-1}\\left\\|k_{b, j}-k_{b, j+1}\\right\\|_{2}因为物体有大动作的时候关键点的含义可能会变化（比如由后腿变成尾巴），所以作者应用随机仿射变换，比较变换后的关键点和变换后的图像提取出的关键点，来保证生成的关键点对任意仿射变换是等变的（equivariant）。即保证了每个关键点语义的一致性，对于一个仿射变换T，等变loss的公式是： \\mathcal{L}_{\\mathrm{eq}}=\\sum_{i=0}^{N_{A}-1}\\left\\|T\\left(E\\left(a_{i}\\right)\\right)-E\\left(T\\left(a_{i}\\right)\\right)\\right\\|_{1}+\\sum_{j=0}^{N_{B}-1}\\left\\|T\\left(E\\left(b_{j}\\right)\\right)-E\\left(T\\left(b_{j}\\right)\\right)\\right\\|_{1}关键点正则化关键点们可能会缩成一个点，因此有额外的两个损失项。 首先惩罚两个过近的关键点： \\mathcal{L}_{\\mathrm{sep}}=\\frac{1}{K^{2}} \\sum_{\\ell=0}^{K-1} \\sum_{\\ell \\neq r}\\left(\\sum_{i=0}^{N_{A}-1} \\max \\left(0, \\delta-\\left\\|k_{a, i}^{\\ell}-k_{a, i}^{r}\\right\\|^{2}\\right)+\\sum_{j=0}^{N_{B}-1} \\max \\left(0, \\delta-\\left\\|k_{b, j}^{\\ell}-k_{b, j}^{r}\\right\\|^{2}\\right)\\right)然后用剪影的损失鼓励关键点待在物体上： \\mathcal{L}_{\\mathrm{sill}}=\\frac{1}{K} \\sum_{\\ell=0}^{K-1}\\left(\\sum_{i=0}^{N_{A}-1}-\\log \\sum_{u, v} s_{a, i}(u, v) H_{a, i}^{\\ell}(u, v)+\\sum_{j=0}^{N_{B}-1}-\\log \\sum_{u, v} s_{b, j}(u, v) H_{b, j}^{\\ell}(u, v)\\right)两步优化大部分损失和形状有关，和纹理无关，所以可以用两步优化目标函数。首先用$\\mathcal{L}_D$训练判别器，同时训练E，$G_A,G_B$。第二步训练$R_A,R_B$。 增强数据有限时可能导致mode collapse。所以作者用随机仿射变换进行增强。因为保留背景是必要的，而这些增强可能会给生成的帧带来伪影（artifact）,所以这些增强直接作用在关键点上，在其传给判别器之前。 预测 得到E,T,G,R之后，用下面的公式得到结果： a b_{j}=R_{A}\\left(G_{A}\\left(T\\left(E\\left(b_{j}\\right)\\right)\\right)\\right)即有a的外观b的动作的第j帧。","link":"/2021/12/13/JOKR-report/"},{"title":"Hello World","text":"是时候建个blog了，参考的2021最全hexo搭建博客+matery美化+使用，写的比较详细。踩的坑都在main和master分支上。以后大概主要写学习相关的文章，记录一下免得忘记。 顺便记录一下config的设置https://hexo.io/zh-cn/docs/configuration.html显示latex公式需要修改一些包，参考：成功解决在hexo中无法显示数学公式的问题","link":"/2021/12/12/hello-world/"},{"title":"跨页表格的题注","text":"使用latex写文章，尤其是和图像相关的文章时，常常会遇到需要用图片表格的情况。为了能够跨页，我们可以使用longtable。因为图片较大，如果没有刻意缩小，那么表格就会跨页。有的文章接收方会要求跨页表格在第二页顶部增加额外的题注来接上上一页的表格，以及第一个题注在表格顶部。 跨页题注https://tex.stackexchange.com/questions/115195/table-captions-continued 给出了一个解决方法。 The package longtable allows you to define a header for the first page by \\endfirsthead a header for all next pages by \\endhead a footer fo all pages expect the last one by \\endfoot a footer for the last page by \\endlastfoot. 这段里的这几个command可以用于控制跨页表格的题注的内容。举例来说，如果我需要在长表格前有个题注，跨页时第二面的表格顶部也有题注，可以这么写： 123456789\\begin{longtable}{ccc}\\caption {Some Members of the Suggested Estimator}\\label{Tab:1}\\\\\\endfirsthead\\caption* {\\textbf{Table \\ref{Tab:1} Continued:} Blablabla}\\\\\\endhead\\endfoot\\endlastfoot%任意内容\\end{longtable} 完整代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374\\begin{longtable}{ccccc}\\caption {本文的算法在VoxCeleb1数据集上得到的结果}\\label{fig:result3}\\\\\\endfirsthead\\caption* {\\textbf{表 \\ref{fig:result3} 接上图:} 本文的算法在VoxCeleb1数据集上得到的结果}\\\\\\endhead\\endfoot\\endlastfoot\\diagbox{原图}{驱动帧} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-0-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-0-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-0-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-0-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-1-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-1-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-1-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-1-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-1-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-2-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-2-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-2-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-2-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-2-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-3-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-3-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-3-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-3-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-3-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-4-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-4-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-4-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-4-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-4-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-5-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-5-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-5-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-5-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/1/gaussian-5-4.png} \\\\\\midrule\\diagbox{原图}{驱动帧} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-0-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-0-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-0-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-0-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-1-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-1-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-1-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-1-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-1-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-2-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-2-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-2-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-2-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-2-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-3-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-3-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-3-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-3-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-3-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-4-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-4-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-4-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-4-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-4-4.png} \\\\\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-5-0.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-5-1.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-5-2.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-5-3.png} &amp;\\includegraphics[width=20mm]{image/appendix1/table/vox/2/gaussian-5-4.png} \\\\\\end{longtable} 也就是说，把想放的内容放在end开头的这几个command之前就可以。上面的代码可以得到下面这个效果： 如果要增加跨页每个表格顶部的横杠，可在\\endfirsthead前面加，比如： 12345678910\\begin{longtable}{ccc}\\caption {Some Members of the Suggested Estimator}\\label{Tab:1}\\\\\\toprule\\endfirsthead\\caption* {\\textbf{Table \\ref{Tab:1} Continued:} Blablabla}\\\\\\endhead\\endfoot\\bottomrule\\endlastfoot%任意内容\\end{longtable}","link":"/2022/05/06/table-caption-continued/"},{"title":"在latex项目里用plotneuralnet","text":"plotneuralnet是一个绘制神经网络的工具，使用该工具可以将python脚本转换为latex脚本，编译得到pdf。需要以下几个步骤： 下载plotneuralnet的github源码，https://github.com/HarisIqbal88/PlotNeuralNet 找一个latex环境，可以是win/linux/overleaf，前两种需要安装latex的环境，比如texlive，可以参考https://github.com/luanshiyinyang/PlotNeuralNet，texlive在这里可以找到https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/。 写好脚本my_arch.py（名字可以随便起）放在源码的pyexamples文件夹下，编写的教程可以在其他地方搜到。 直接用python运行python my_arch.py，可以看到目录下的my_arch.tex 这样就得到了一个能够直接编译的tex文件。但是实际上很多情况下我们想把这个放进自己的项目里。我以一个比较大的tex项目为例，文件夹结构大致如下： 查看文件夹结构 . ├── Makefile ├── README.md ├── bibtex-style │ ├── gbt7714-2005.bst │ ├── thesis.bst │ └── thesis2.bst ├── code │ └── demo.cpp ├── ctex-fontset-adobe2.def ├── docs │ ├── abstract.tex │ ├── ack.tex │ ├── appendix1.tex │ ├── chap01.tex │ ├── chap02.tex │ ├── chap03.tex │ ├── chap04.tex │ ├── chap05.tex │ ├── chap06.tex │ ├── disclaim.tex │ ├── grading.tex │ ├── info.tex │ ├── progress.tex │ └── proposal.tex ├── fonts │ └── init_fonts.sh ├── gulpfile.js ├── image │ ├── appendix1 │ ├── chap03 │ │ ├── overleaf-config.jpg │ │ ├── overleaf-create-proj.jpg │ │ ├── overleaf-example.jpg │ │ ├── overleaf-upload-proj.jpg │ │ └── vscode-example.png │ ├── chap04 │ │ ├── example │ │ │ ├── 2007_000799.jpg │ │ └── result │ │ ├── compare │ │ │ └── zoom_dog.png │ │ └── error │ │ └── p_2008_001580.png │ └── template │ ├── readme.md │ └── logo.pdf ├── main.bib ├── main.pdf ├── main.tex ├── package.json ├── packages │ ├── algorithm2e.sty │ ├── algorithm2e.tex │ └── ctex-xecjk-adobefonts.def │ └── thubeamer.sty ├── code.sty └── thesis.cls 实际上只需要关心docs文件夹和main.tex，因为神经网络结构一般放在正文里。 以放入docs的chap03.tex为例，需要以下步骤： 将源码的layers文件夹放进自己的项目文件夹。 把my_arch.tex中这几行的内容（里面的配置可以调整）放入main.tex（最外层的文档）的序言（preamble）区，也就是放\\usepackage的区域里。 123\\documentclass[border=8pt, multi, tikz]{standalone} \\usepackage{import}\\subimport{../layers/}{init} 调整subimport里面的layers的路径，按照第一步来做，则应该改成\\subimport{layers/}{init}。 接下来将神经网络结构放入正文，把my_arch.tex里除上面这几行之外的内容完整地拷贝到chap03.tex里自己想放的位置。要去掉\\begin{document}和\\end{document}。 如果代码里有includegraphics，要把对应的图片放在对应的文件夹下。 编译就可以看到结果。 这样做会看到神经网络图片非常大，超出了页面。因为这个模块是tikzpicture的，所以可以用TikZ的方法来调整。 以整体缩放为例，参考在 LaTeX 中同步缩放 TikZ 与其中的 node，可以在\\begin{tikzpicture}上面加入下面这段代码： 12345\\tikzset{global scale/.style={ scale=#1, every node/.append style={scale=#1} }} 然后把\\begin{tikzpicture}改成\\begin{tikzpicture}[scale=0.5]，就能把整个大小缩放为原来的0.5倍。","link":"/2022/03/16/plotneuralnet-in-a-project/"},{"title":"浮点数","text":"浮点数的表示方法为 v=(-l)^s M 2^E对于规范化编码(Normalized Encoding)，M是frac的部分加1得到的，所以能表示的最小的正数是$2^{E_{min}}$。因此需要引入非规范化编码(Denormalized Encoding)，它的M不需要加1，E=1-Bias。最小的数是0。","link":"/2023/01/05/float-number/"},{"title":"程序优化","text":"C代码中有许多比较通用的可以优化的地方。其中大部分优化方式在其他语言中也是有效的。 减弱强度使用指令个数更少的代码或者需要总的时钟周期更少的代码代替原代码，比如位移动代替乘法除法等。 使用局部变量(代码移动)表达式如果某些表达式被重复计算了，可以提前保存。一般来说O1以上会自动开启此优化。 12345678// 1.cint t(int i){ int x=3+i*i; int y=4+i*i; int z=5+i*i; int xx=x/y+y/z+z; return xx;} 用-S生成汇编，-Ox指定优化等级： 1gcc 1.c -S 使用上面的命令结果为： 1234567891011121314151617181920212223242526272829303132333435363738t: pushq %rbp .seh_pushreg %rbp movq %rsp, %rbp .seh_setframe %rbp, 0 subq $16, %rsp .seh_stackalloc 16 .seh_endprologue movl %ecx, 16(%rbp) movl 16(%rbp), %eax imull 16(%rbp), %eax addl $3, %eax movl %eax, -4(%rbp) movl 16(%rbp), %eax imull 16(%rbp), %eax addl $4, %eax movl %eax, -8(%rbp) movl 16(%rbp), %eax imull 16(%rbp), %eax addl $5, %eax movl %eax, -12(%rbp) movl -4(%rbp), %eax cltd idivl -8(%rbp) movl %eax, %ecx movl -8(%rbp), %eax cltd idivl -12(%rbp) leal (%rcx,%rax), %edx movl -12(%rbp), %eax addl %edx, %eax movl %eax, -16(%rbp) movl -16(%rbp), %eax addq $16, %rsp popq %rbp ret .seh_endproc .ident &quot;GCC: (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 8.1.0&quot; 1gcc 1.c -S -O1 使用上面的命令结果为：123456789101112131415161718192021222324 .file &quot;1.c&quot; .text .globl t .def t; .scl 2; .type 32; .endef .seh_proc tt: .seh_endprologue imull %ecx, %ecx leal 4(%rcx), %r8d leal 5(%rcx), %r9d addl $3, %ecx movl %ecx, %eax cltd idivl %r8d movl %eax, %ecx movl %r8d, %eax cltd idivl %r9d addl %ecx, %eax addl %r9d, %eax ret .seh_endproc .ident &quot;GCC: (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 8.1.0&quot;可见gcc是会主动优化该类型的冗余代码的。 函数调用循环等过程中重复调用函数会花非常多的不必要的时间。因为编译器对此函数一无所知，如果存在副作用则优化后程序的结果会与优化前不一样，所以会避免对其使用优化。应主动使用局部变量来保存此重复调用的函数。 内存别名如果赋值时使用了内存中的值，可以换成用局部变量保存（比如循环中保存累加的值），这样可以避免编译器无法判断此段代码是否使用了内存别名（比如对数组求和但是保存在数组内部）。因为优化后会得到不一样的结果而不进行优化。下面是这个例子 12345678910void sum_rows1(double *a, double *b, long n){ long i, j; for (i = 0; i &lt; n; i++) { b[i] = 0; for (j = 0; j &lt; n; j++) b[i] += a[i*n + j]; }} 可以用局部变量代替b[i]。1234567891011void sum_rows2(double *a, double *b, long n){ long i, j; for (i = 0; i &lt; n; i++) { double val = 0; for (j = 0; j &lt; n; j++) val += a[i*n + j]; b[i] = val; }} 针对机器对代码进行调整计算重排此部分针对于流水线CPU，对部分代码进行重排可以更高效利用ALU。对于表达式来说，其中如果表达式右边包含多个乘法，则可以使用多个单次乘法及赋值代替一次全部乘起来。这样会避免内存的依赖，因此流水线处理器可以保证每个乘法同时处于执行的不同阶段，而不会需要等待上一条指令写回后再执行下一条。 下面的代码里，将一个数组中各个元素乘起来，用x保存。这里用一次乘两个元素的方式减少了一半赋值语句。12345678910111213141516171819void unroll2a_combine(vec__ptr v, data_t *dest){ long length = vec_length(v); long limit = length - 1; data_t *d = get_vec_start(v); data_t x = IDENT; long i; /* Combine 2 elements at a time */ for (i = 0; i &lt; limit; i += 2) { x = (x OP d[i])OP d[i + l]; } /* Finish any remaining elements */ for (; i &lt; length; i++) { x = x OP d[i]; } *dest = x;}但是仍然有优化空间，因为这里每次都乘到x上，需要等x更新完才能继续下一次计算，流水线上其他元件不能不闲着。将乘数全部换成d中的元素，则每次执行时都没有互相的内存依赖（d[0],d[1]一组，d[2],d[3]一组，互不依赖）。12345678910111213141516171819void unroll2a_combine(vec__ptr v, data_t *dest){ long length = vec_length(v); long limit = length - 1; data_t *d = get_vec_start(v); data_t x = IDENT; long i; /* Combine 2 elements at a time */ for (i = 0; i &lt; limit; i += 2) { x = x OP (d[i] OP d[i + l]); } /* Finish any remaining elements */ for (; i &lt; length; i++) { x = x OP d[i]; } *dest = x;}这样可能存在的问题是，浮点数乘法不一定满足结合律，但是对于目前我们常使用的位数（32，64）即使存在误差，大部分时间是可以接受的。这个优化方法叫做循环展开（loop unrolling）。 避免无法预测的分支条件移动可以在流水线中进行，条件跳转则如果遇到不可预测的分支可能出现预测（此时会执行预测结果开始的指令，但是不修改寄存器和内存）失败而直接回到分支前重新执行。 条件移动的例子是： 123456long f(long x,long y){ long res; if(x&gt;y)res=x-y; else res=y-x; return res;} 汇编为：12345678910111213141516 .file &quot;1.c&quot; .text .globl f .def f; .scl 2; .type 32; .endef .seh_proc ff: .seh_endprologue movl %ecx, %r8d subl %edx, %r8d movl %edx, %eax subl %ecx, %eax cmpl %edx, %ecx cmovg %r8d, %eax ret .seh_endproc .ident &quot;GCC: (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 8.1.0&quot;可以看到使用了cmovg来设置返回值%eax，否的情况则跳过。 如果使用下面的命令进行编译，汇编里就会使用条件分支。 1gcc 1.c -S -O1 -fno-if-conversion 123456789101112131415161718192021 .file &quot;1.c&quot; .text .globl f .def f; .scl 2; .type 32; .endef .seh_proc ff: .seh_endprologue cmpl %edx, %ecx jle .L2 movl %ecx, %eax subl %edx, %eax.L1: ret.L2: movl %edx, %eax subl %ecx, %eax jmp .L1 .seh_endproc .ident &quot;GCC: (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 8.1.0&quot;} 这里是题外话，一般来说需要避免条件移动，有两个原因： 他会将两个分支都进行计算，但是实际上两个分支的内容有多复杂是不知道的，有可能会额外执行非常多无意义的指令，而且有可能某分支的内容对于当前条件是非法的（比如对空指针进行解引用）。对GCC一般来说只有两个分支都是非常简单的语句才会使用。 不必要执行的分支可能存在副作用。 这部分我的理解是，不要写太多奇怪的条件语句，尤其是循环内部，这样会使得预测结果错误比较频繁。比如如果只是最后退出循环的时候条件预测错了一次，开销相对整体的多次循环并不算很大。","link":"/2023/01/10/program-optimization/"},{"title":"光线投射（raycast）公式中的far-clip","text":"光线投射公式从相机发出一条光线，穿过与相机距离为1的屏幕上的某点，已知相机参数和点在屏幕空间上的位置(sx,sy)，计算世界空间中投影到该点的对应点的坐标的公式为： P = ViewMat^{-1} * ProjMat^{-1} * ((sx, sy, 1, 1) * farClip).使用下面的公式得到的结果实际上是一样的。 P = ViewMat^{-1} * ProjMat^{-1} * (sx, sy, 1, 1),但是需要对向量进行规范化，即： P=[p.x,p.y,p.z,p.w]/p.w. 证明投影公式ProjMat为: P=\\begin{bmatrix} \\frac{1}{A\\tan(FOV/2)} & 0 & 0 & 0 \\\\ 0 & \\frac{1}{\\tan(FOV/2)} & 0 & 0 \\\\ 0 & 0 & \\frac{f}{f-n} & \\frac{-fn}{f-n}\\\\ 0 & 0 & 1 & 0 \\end{bmatrix}.因为ViewMat是齐次矩阵，不修改w，所以只考虑投影公式。首先计算它的逆。因为左下角与右上角为0，可以视为$2\\times 2$的分块矩阵，计算逆时只需要计算右下角的逆即可。左上角为对角矩阵，逆是对角元素的倒数。2维矩阵较小，可以用伴随矩阵计算逆。伴随矩阵公式为： adj({ {\\begin{bmatrix}{a}&{b}\\\\{c}&{d}\\end{bmatrix} }})={ {\\begin{bmatrix}\\,\\,\\,{d}&\\!\\!{-b}\\\\{-c}&{a}\\end{bmatrix} }}.关于n×n矩阵A，有 \\mathbf{A}\\, \\mathrm{adj}(\\mathbf{A}) = \\mathrm{adj}(\\mathbf{A})\\, \\mathbf{A} = \\det(\\mathbf{A})\\, \\mathbf{I}.即 \\mathbf{A}^{-1} = \\det(\\mathbf{A})^{-1}\\, \\mathrm{adj}(\\mathbf{A})令 A=\\begin{bmatrix} \\frac{f}{f-n} & \\frac{-fn}{f-n}\\\\ 1 & 0 \\end{bmatrix}则 det(A)=\\frac{fn}{f-n}.\\\\ A^{-1}=\\frac{1}{\\frac{fn}{f-n} }\\begin{bmatrix} 0 & \\frac{fn}{f-n}\\\\ -1 & \\frac{f}{f-n} \\end{bmatrix}=\\begin{bmatrix} 0 & 1\\\\ -\\frac{f-n}{fn} & \\frac{1}{n} \\end{bmatrix}因此投影矩阵的逆为： P^{-1}=\\begin{bmatrix} {A\\tan(FOV/2)} & 0 & 0 & 0 \\\\ 0 & {\\tan(FOV/2)} & 0 & 0 \\\\ 0 & 0 & 0 & 1\\\\ 0 & 0 & -\\frac{f-n}{fn} & \\frac{1}{n} \\end{bmatrix}根据公式： \\begin{bmatrix} sx\\\\ sy\\\\ 1\\\\ 1 \\end{bmatrix} \\times farClip= \\begin{bmatrix} sx\\times farClip\\\\ sy\\times farClip\\\\ farClip\\\\ farClip \\end{bmatrix}, P^{-1}*\\begin{bmatrix} sx\\times farClip\\\\ sy\\times farClip\\\\ farClip\\\\ farClip \\end{bmatrix}= \\begin{bmatrix} {A\\tan(FOV/2)}sx\\times farClip\\\\ {\\tan(FOV/2)}sy\\times farClip\\\\ farClip\\\\ 1 \\end{bmatrix}对比直接相乘的结果： P^{-1}*\\begin{bmatrix} sx\\\\ sy\\\\ 1\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} {A\\tan(FOV/2)}sx\\\\ {\\tan(FOV/2)}sy\\\\ 1\\\\ 1 \\end{bmatrix}= \\begin{bmatrix} {A\\tan(FOV/2)}sx\\\\ {\\tan(FOV/2)}sy\\\\ 1\\\\ \\frac{1}{f} \\end{bmatrix}可以看出，无论乘不乘farClip规范化后的结果确实是一样的。但是因为glm并没有提供我们需要的规范化的函数，所以通过乘farClip来省去手动规范化的步骤是可以提高效率的。","link":"/2023/01/14/raycast-formula/"}],"tags":[{"name":"图像动画","slug":"图像动画","link":"/tags/%E5%9B%BE%E5%83%8F%E5%8A%A8%E7%94%BB/"},{"name":"计算机视觉","slug":"计算机视觉","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"latex","slug":"latex","link":"/tags/latex/"},{"name":"神经网络可视化","slug":"神经网络可视化","link":"/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"计算机组成原理","slug":"计算机组成原理","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"},{"name":"学习","slug":"学习","link":"/tags/%E5%AD%A6%E4%B9%A0/"},{"name":"计算机图形学","slug":"计算机图形学","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"CIS-5610","slug":"CIS-5610","link":"/tags/CIS-5610/"}],"categories":[{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"},{"name":"论文笔记","slug":"学习/论文笔记","link":"/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"图像动画","slug":"学习/论文笔记/图像动画","link":"/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9B%BE%E5%83%8F%E5%8A%A8%E7%94%BB/"},{"name":"文章排版","slug":"学习/文章排版","link":"/categories/%E5%AD%A6%E4%B9%A0/%E6%96%87%E7%AB%A0%E6%8E%92%E7%89%88/"},{"name":"工具使用","slug":"学习/工具使用","link":"/categories/%E5%AD%A6%E4%B9%A0/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/"},{"name":"计算机组成原理","slug":"学习/计算机组成原理","link":"/categories/%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}],"pages":[{"title":"about","text":"对图形学感兴趣，懂一点AI的在读研究生。","link":"/about/index.html"},{"title":"所有标签","text":"","link":"/tags/index.html"},{"title":"所有分类","text":"","link":"/categories/index.html"}]}